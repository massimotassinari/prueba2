{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import a library with an alias\n",
    "import pandas as pd\n",
    "\n",
    "# import a module from a package\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# File paths - Update these with your actual file locations\n",
    "SHARE_PRICES_FILE = \"data/simfin_data/us-shareprices-daily.csv\"\n",
    "COMPANY_INFO_FILE = \"data/simfin_data/us-companies.csv\"\n",
    "\n",
    "# Load Share Prices Data\n",
    "df_share_prices = pd.read_csv(SHARE_PRICES_FILE, delimiter=';', parse_dates=['Date'])\n",
    "print(\"‚úÖ Share Prices Data Loaded. Shape:\", df_share_prices.shape)\n",
    "\n",
    "# Load Company Info Data\n",
    "df_company = pd.read_csv(COMPANY_INFO_FILE, delimiter=';')\n",
    "print(\"‚úÖ Company Info Data Loaded. Shape:\", df_company.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Handiling columns name convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example transformations:\n",
    "df_share_prices.columns = [col.strip().lower().replace(\" \", \"_\") for col in df_share_prices.columns]  # Normalize column names\n",
    "# Example transformations:\n",
    "df_company.columns = [col.strip().lower().replace(\" \", \"_\") for col in df_company.columns]  # Normalize column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share_prices['date'] = pd.to_datetime(df_share_prices['date'])  # Convert date columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share_prices.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Checking for null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Share prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df_share_prices.isnull().sum())  # Count of nulls per column\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(df_share_prices.isnull(), cmap=\"viridis\", cbar=False, yticklabels=False)\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of missing values per column\n",
    "null_percentage = (df_share_prices.isnull().sum() / len(df_share_prices)) * 100\n",
    "\n",
    "# Display the result\n",
    "print(null_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1.1 Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Share Prices Data\n",
    "def clean_share_prices(df):\n",
    "    df = df.copy()  # Avoid chained assignment warnings\n",
    "    df = df.drop(columns=['dividend'], errors='ignore')  # Drop the dividend column\n",
    "    df = df.assign(\n",
    "        shares_outstanding=df['shares_outstanding'].ffill()  # Forward fill missing shares outstanding\n",
    "    )\n",
    "    df = df.sort_values(by=['ticker', 'date'])\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply Cleaning Functions\n",
    "df_share_prices_cleaned = clean_share_prices(df_share_prices)\n",
    "\n",
    "\n",
    "# Check Results\n",
    "print(\"‚úÖ Share Prices Cleaned. Shape:\", df_share_prices_cleaned.shape)\n",
    "\n",
    "print(\"üîç Missing Values in Share Prices:\\n\", df_share_prices_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df_company.isnull().sum())  # Count of nulls per column\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(df_company.isnull(), cmap=\"viridis\", cbar=False, yticklabels=False)\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of missing values per column\n",
    "null_percentage = (df_company.isnull().sum() / len(df_company)) * 100\n",
    "\n",
    "# Display the result\n",
    "print(null_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Company Info Data\n",
    "def clean_company_info(df):\n",
    "    df = df.copy()  # Avoid chained assignment warnings\n",
    "    \n",
    "    # Drop rows where ticker is missing (since we need it for merging)\n",
    "    df = df.dropna(subset=['ticker'])\n",
    "    \n",
    "    # Fill missing values\n",
    "    df = df.assign(\n",
    "        company_name=df['company_name'].fillna('Unknown'),\n",
    "        industryid=df['industryid'].fillna(-1).astype('category'),  # Fill with -1 and convert to category\n",
    "        end_of_financial_year_month=df['end_of_financial_year_(month)'].fillna(df['end_of_financial_year_(month)'].mode()[0]),  # Fill with most frequent value\n",
    "        number_employees=df['number_employees'].fillna(df['number_employees'].median()),  # Fill missing with median\n",
    "        business_summary=df['business_summary'].fillna('No summary available')\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply Cleaning Function\n",
    "df_company_cleaned = clean_company_info(df_company)\n",
    "\n",
    "# Check Missing Values Again\n",
    "print(\"‚úÖ Company Info Cleaned. Shape:\", df_company_cleaned.shape)\n",
    "print(\"üîç Missing Values in Company Info:\\n\", df_company_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Share Prices with Company Info\n",
    "def merge_datasets(share_prices, company_info):\n",
    "    merged_df = share_prices.merge(company_info, on='ticker', how='left')\n",
    "    return merged_df\n",
    "\n",
    "# Apply Merge\n",
    "df_merged = merge_datasets(df_share_prices_cleaned, df_company_cleaned)\n",
    "\n",
    "# Check Results\n",
    "print(\"‚úÖ Merged Data Shape:\", df_merged.shape)\n",
    "print(\"üîç Missing Values After Merge:\\n\", df_merged.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Final clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merged.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant 'simfinid_y' column (keeping 'simfinid_x' as 'simfinid')\n",
    "df_merged = df_merged.drop(columns=['simfinid_y']).rename(columns={'simfinid_x': 'simfinid'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataset\n",
    "output_path = \"processed_data\"\n",
    "df_merged.to_csv(f\"{output_path}.csv\", index=False)\n",
    "df_merged.to_parquet(f\"{output_path}.parquet\")\n",
    "\n",
    "# Check final structure\n",
    "print(\"‚úÖ Final Processed Data Shape:\", df_merged.shape)\n",
    "print(\"üîç Missing Values in Final Data:\\n\", df_merged.isnull().sum())\n",
    "print(\"üìÇ Data saved successfully as CSV and Parquet!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preparing the Model Table Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_company_data(df, ticker):\n",
    "    \"\"\"\n",
    "    Prepare model data for a specific company based on its ticker.\n",
    "    \"\"\"\n",
    "    df_company = df[df['ticker'] == ticker].copy()  # Filter for selected company\n",
    "    \n",
    "    # Ensure data is sorted correctly\n",
    "    df_company = df_company.sort_values(by='date')\n",
    "\n",
    "    # Creating lag features (last 3 days closing prices)\n",
    "    df_company['close_t-1'] = df_company['close'].shift(1)\n",
    "    df_company['close_t-2'] = df_company['close'].shift(2)\n",
    "    df_company['close_t-3'] = df_company['close'].shift(3)\n",
    "\n",
    "    # Target Variable: Next day's price movement (1 if up, 0 if down)\n",
    "    df_company['target'] = (df_company['close'].shift(-1) > df_company['close']).astype(int)\n",
    "\n",
    "    # Drop NaN values caused by shifting\n",
    "    df_company.dropna(inplace=True)\n",
    "\n",
    "    return df_company[['date', 'close_t-3', 'close_t-2', 'close_t-1', 'target']]\n",
    "\n",
    "# Specify a company ticker\n",
    "selected_ticker = \"AAPL\"  # Change this to test different companies\n",
    "\n",
    "# Apply the function\n",
    "df_company_model = prepare_company_data(df_merged, selected_ticker)\n",
    "\n",
    "# Check the processed data\n",
    "print(f\"‚úÖ Data Prepared for {selected_ticker}. Shape:\", df_company_model.shape)\n",
    "print(\"üîç Sample Data:\\n\", df_company_model.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Traing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ‚úÖ Ensure Data is Numeric (Fixing Categorical Columns)\n",
    "def prepare_xgboost_data(df):\n",
    "    \"\"\"\n",
    "    Ensure the dataset is numeric by dropping text columns and encoding categorical features.\n",
    "    \"\"\"\n",
    "    # Drop non-numeric columns that don't contribute to the model\n",
    "    cols_to_drop = ['ticker', 'company_name', 'isin', 'business_summary', 'market', 'main_currency']\n",
    "    df = df.drop(columns=[col for col in cols_to_drop if col in df.columns], errors='ignore')\n",
    "\n",
    "    # Convert categorical columns to numeric (if needed)\n",
    "    if 'industryid' in df.columns:\n",
    "        df['industryid'] = df['industryid'].astype('category').cat.codes  # Convert to numeric codes\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the fix before training\n",
    "df_company_model_fixed = prepare_xgboost_data(df_company_model)\n",
    "\n",
    "print(\"‚úÖ Data Preparation Complete. Shape:\", df_company_model_fixed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set SimFin API Key (Replace with your actual key)\n",
    "sf.set_api_key('344dd533-861f-4bef-9f52-be02f0276014')\n",
    "\n",
    "# Set SimFin Data Directory (for caching data)\n",
    "sf.set_data_dir('simfin_data')\n",
    "\n",
    "def get_latest_stock_data(ticker):\n",
    "    \"\"\"\n",
    "    Fetch the latest available stock data (Close Price, Volume, etc.) from SimFin.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch daily stock price data\n",
    "        df = sf.load_shareprices(variant='daily', market='us')\n",
    "\n",
    "        # Ensure 'Ticker' exists in the index\n",
    "        if ticker not in df.index.get_level_values(0):\n",
    "            print(f\"‚ùå No data found for ticker: {ticker}\")\n",
    "            return None\n",
    "\n",
    "        # Select only the specified ticker using index filtering\n",
    "        df_ticker = df.loc[ticker].copy()\n",
    "\n",
    "        # Get the latest row\n",
    "        latest_row = df_ticker.iloc[-1]  \n",
    "\n",
    "        # Extract required features\n",
    "        latest_data = {\n",
    "            'close_t-1': df_ticker['Close'].shift(1).iloc[-1],\n",
    "            'close_t-2': df_ticker['Close'].shift(2).iloc[-1],\n",
    "            'close_t-3': df_ticker['Close'].shift(3).iloc[-1],\n",
    "            'close_t-4': df_ticker['Close'].shift(4).iloc[-1],\n",
    "            'close_t-5': df_ticker['Close'].shift(5).iloc[-1],\n",
    "            'vol_ma_5': df_ticker['Volume'].rolling(window=5).mean().iloc[-1],\n",
    "            'vol_ma_10': df_ticker['Volume'].rolling(window=10).mean().iloc[-1],\n",
    "            'day_of_week': latest_row.name.dayofweek,  # Monday=0, Sunday=6\n",
    "            'month': latest_row.name.month\n",
    "        }\n",
    "\n",
    "        # Convert to DataFrame (for prediction)\n",
    "        latest_df = pd.DataFrame([latest_data])\n",
    "\n",
    "        print(\"‚úÖ Latest Stock Data Fetched from SimFin!\")\n",
    "        return latest_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error Fetching Data from SimFin: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with a known stock symbol\n",
    "get_latest_stock_data(\"A\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_final(df_company_model):\n",
    "    \"\"\"\n",
    "    Train an optimized XGBoost model using RandomizedSearchCV for better accuracy.\n",
    "    \"\"\"\n",
    "    # Ensure 'target' column exists\n",
    "    if 'target' not in df_company_model.columns:\n",
    "        print(\"‚ùå Error: 'target' column is missing. Recalculating it now.\")\n",
    "        df_company_model['target'] = (df_company_model['close'].shift(-1) > df_company_model['close']).astype(int)\n",
    "\n",
    "    # Splitting Features (X) and Target (y)\n",
    "    cols_to_drop = ['date', 'close', 'target']\n",
    "    cols_to_drop = [col for col in cols_to_drop if col in df_company_model.columns]  # Drop only if they exist\n",
    "\n",
    "    X = df_company_model.drop(columns=cols_to_drop)\n",
    "    y = df_company_model['target']\n",
    "\n",
    "    # Train-Test Split (80% Train, 20% Test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Define XGBoost Model\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "    # Final Optimized Hyperparameters\n",
    "    param_dist = {\n",
    "        'n_estimators': [200, 300, 400],\n",
    "        'learning_rate': [0.05, 0.1, 0.15],\n",
    "        'max_depth': [3, 5],\n",
    "        'min_child_weight': [1, 3],\n",
    "        'gamma': [0, 0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8],\n",
    "        'scale_pos_weight': [1.2, 1.5]  # Adjusting for class imbalance\n",
    "    }\n",
    "\n",
    "    # Perform Randomized Search\n",
    "    rand_search = RandomizedSearchCV(\n",
    "        model, param_distributions=param_dist, n_iter=15,\n",
    "        scoring='accuracy', cv=3, n_jobs=-1, random_state=42\n",
    "    )\n",
    "\n",
    "    rand_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best Model\n",
    "    best_model = rand_search.best_estimator_\n",
    "\n",
    "    # Make Predictions\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Evaluate Performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"‚úÖ Final XGBoost Model Training Complete!\")\n",
    "    print(f\"üìä Best Hyperparameters: {rand_search.best_params_}\")\n",
    "    print(f\"üìä Final Optimized Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nüîç Classification Report:\\n\", report)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Train the final optimized model\n",
    "xgb_model_final = train_xgboost_final(df_company_model_fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model as a binary file\n",
    "joblib.dump(xgb_model_final, \"xgb_model_final.pkl\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print features used during model training\n",
    "print(\"‚úÖ Features Used in Training:\", xgb_model_final.feature_names_in_)\n",
    "\n",
    "# Fetch latest stock data\n",
    "latest_data = get_latest_stock_data(\"AAPL\")\n",
    "\n",
    "# Print features from API data\n",
    "print(\"‚úÖ Features from SimFin API:\", latest_data.columns if latest_data is not None else \"No data fetched\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_xgboost_api(model, ticker):\n",
    "    \"\"\"\n",
    "    Fetch latest stock data from SimFin and predict whether the stock will go up or down.\n",
    "    \"\"\"\n",
    "    # Fetch latest stock data from SimFin API\n",
    "    latest_data = get_latest_stock_data(ticker)\n",
    "\n",
    "    if latest_data is None:\n",
    "        print(\"‚ùå Could not retrieve latest stock data. Aborting prediction.\")\n",
    "        return\n",
    "\n",
    "    # Ensure feature alignment: Keep only the features used in training\n",
    "    model_features = model.feature_names_in_\n",
    "    latest_data = latest_data[model_features]  # Select only relevant columns\n",
    "\n",
    "    # Make Prediction\n",
    "    prediction = model.predict(latest_data)\n",
    "    prediction_label = \"üìà Up\" if prediction[0] == 1 else \"üìâ Down\"\n",
    "\n",
    "    print(f\"üîÆ XGBoost Prediction for {ticker}: {prediction_label}\")\n",
    "\n",
    "# Example Usage: Predict for AAPL\n",
    "predict_next_day_xgboost_api(xgb_model_final, \"AAPL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Spliting testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class SimFinAPI:\n",
    "    BASE_URL = \"https://simfin.com/api/v2/companies/prices/list\"\n",
    "    API_KEY = \"344dd533-861f-4bef-9f52-be02f0276014\"  # Replace with your actual SimFin API key\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize API wrapper with headers.\"\"\"\n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"api-key {self.API_KEY}\"\n",
    "        }\n",
    "\n",
    "    def get_latest_stock_data(self, ticker):\n",
    "        \"\"\"\n",
    "        Fetch the latest available stock data (Close Price, Volume, etc.) from SimFin.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Define request parameters\n",
    "            params = {\n",
    "                \"ticker\": ticker,\n",
    "                \"timeframe\": \"daily\",\n",
    "                \"start\": \"2024-01-01\",  # Adjust as needed\n",
    "                \"end\": \"2024-12-31\"\n",
    "            }\n",
    "\n",
    "            # Send API request\n",
    "            response = requests.get(self.BASE_URL, headers=self.headers, params=params)\n",
    "\n",
    "            # Print Full Response for Debugging\n",
    "            print(\"üîç Full API Response:\", response.status_code, response.text)\n",
    "\n",
    "            # Handle errors\n",
    "            if response.status_code != 200:\n",
    "                print(f\"‚ùå Error Fetching Data: {response.json().get('error', 'Unknown error')}\")\n",
    "                return None\n",
    "\n",
    "            # Parse JSON response\n",
    "            data = response.json()\n",
    "\n",
    "            print(\"‚úÖ API Request Successful!\")\n",
    "            return data  # Return raw data for now\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Exception Fetching Data from SimFin: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize API Wrapper\n",
    "simfin_api = SimFinAPI()\n",
    "\n",
    "# Test with a known ticker (AAPL)\n",
    "api_response = simfin_api.get_latest_stock_data(\"AAPL\")\n",
    "print(\"üîç Raw API Response:\", api_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://backend.simfin.com/api/v3/companies/common-shares-outstanding?ticker=AAPL&start=2025-01-01\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"api-key 344dd533-861f-4bef-9f52-be02f0276014\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Set your API key\n",
    "API_KEY = \"344dd533-861f-4bef-9f52-be02f0276014\"\n",
    "\n",
    "# Define the endpoint (use company ID, not ticker)\n",
    "company_id = 59265  # Example: Apple Inc.'s ID on SimFin\n",
    "url = f\"https://simfin.com/api/v2/companies/id/{company_id}/shares/prices\"\n",
    "\n",
    "# Define the parameters\n",
    "params = {\n",
    "    \"api-key\": API_KEY,\n",
    "    \"start\": \"2023-01-01\",  # Replace with your desired start date\n",
    "    \"end\": \"2024-03-11\",  # Replace with your desired end date\n",
    "    \"timeframe\": \"d\"  # 'd' for daily, 'w' for weekly, 'm' for monthly\n",
    "}\n",
    "\n",
    "# Make the GET request\n",
    "response = requests.get(url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Convert response to JSON\n",
    "    if 'data' in data:  # Ensure there is data in response\n",
    "        df = pd.DataFrame(data['data'], columns=data['columns'])  # Convert to DataFrame\n",
    "        print(df.head())  # Print the first few rows\n",
    "    else:\n",
    "        print(\"No data found in response.\")\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Standarize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Training using logistic regresion model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Evaluation of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Company Info Retrieved for AAPL\n",
      "‚úÖ Company Data Processed for AAPL\n",
      "2025-02-12\n",
      "‚úÖ Stock Price Data Retrieved for AAPL (from 2025-02-12)\n",
      "‚úÖ Stock Data Processed for AAPL\n"
     ]
    }
   ],
   "source": [
    "import api_functions as api\n",
    "simfin = api.SimFinAPI('AAPL')\n",
    "\n",
    "# Fetch company info and stock data (defaults to last two weeks)\n",
    "simfin.fetch_company_info()\n",
    "simfin.fetch_stock_data()  # Uses last two weeks by default\n",
    "\n",
    "df_company = simfin.get_company_dataframe()\n",
    "df_stock = simfin.get_stock_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companyDescription</th>\n",
       "      <th>endFy</th>\n",
       "      <th>id</th>\n",
       "      <th>industryName</th>\n",
       "      <th>isin</th>\n",
       "      <th>market</th>\n",
       "      <th>name</th>\n",
       "      <th>numEmployees</th>\n",
       "      <th>sectorCode</th>\n",
       "      <th>sectorName</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple Inc is an American multinational technol...</td>\n",
       "      <td>9</td>\n",
       "      <td>111052</td>\n",
       "      <td>Technology</td>\n",
       "      <td>US0378331005</td>\n",
       "      <td>US</td>\n",
       "      <td>APPLE INC</td>\n",
       "      <td>147000</td>\n",
       "      <td>101001</td>\n",
       "      <td>Computer Hardware</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  companyDescription  endFy      id  \\\n",
       "0  Apple Inc is an American multinational technol...      9  111052   \n",
       "\n",
       "  industryName          isin market       name  numEmployees  sectorCode  \\\n",
       "0   Technology  US0378331005     US  APPLE INC        147000      101001   \n",
       "\n",
       "          sectorName ticker  \n",
       "0  Computer Hardware   AAPL  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Dividend Paid</th>\n",
       "      <th>Common Shares Outstanding</th>\n",
       "      <th>Last Closing Price</th>\n",
       "      <th>Adjusted Closing Price</th>\n",
       "      <th>Highest Price</th>\n",
       "      <th>Lowest Price</th>\n",
       "      <th>Opening Price</th>\n",
       "      <th>Trading Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-12</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>236.87</td>\n",
       "      <td>236.87</td>\n",
       "      <td>236.96</td>\n",
       "      <td>230.68</td>\n",
       "      <td>231.20</td>\n",
       "      <td>44996462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-13</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>241.53</td>\n",
       "      <td>241.53</td>\n",
       "      <td>242.34</td>\n",
       "      <td>235.57</td>\n",
       "      <td>236.91</td>\n",
       "      <td>52138207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>244.60</td>\n",
       "      <td>244.60</td>\n",
       "      <td>245.55</td>\n",
       "      <td>240.99</td>\n",
       "      <td>241.25</td>\n",
       "      <td>40185610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-18</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>244.47</td>\n",
       "      <td>244.47</td>\n",
       "      <td>245.18</td>\n",
       "      <td>241.84</td>\n",
       "      <td>244.15</td>\n",
       "      <td>48111486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-19</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>244.87</td>\n",
       "      <td>244.87</td>\n",
       "      <td>246.01</td>\n",
       "      <td>243.16</td>\n",
       "      <td>244.66</td>\n",
       "      <td>32140384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-02-20</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>245.83</td>\n",
       "      <td>245.83</td>\n",
       "      <td>246.78</td>\n",
       "      <td>244.29</td>\n",
       "      <td>244.94</td>\n",
       "      <td>31037471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-02-21</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>245.55</td>\n",
       "      <td>245.55</td>\n",
       "      <td>248.69</td>\n",
       "      <td>245.22</td>\n",
       "      <td>245.95</td>\n",
       "      <td>53011988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>247.10</td>\n",
       "      <td>247.10</td>\n",
       "      <td>248.86</td>\n",
       "      <td>244.42</td>\n",
       "      <td>244.93</td>\n",
       "      <td>51031845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-02-25</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>247.04</td>\n",
       "      <td>247.04</td>\n",
       "      <td>250.00</td>\n",
       "      <td>244.91</td>\n",
       "      <td>248.00</td>\n",
       "      <td>47275651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-02-26</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>240.36</td>\n",
       "      <td>240.36</td>\n",
       "      <td>244.98</td>\n",
       "      <td>239.13</td>\n",
       "      <td>244.33</td>\n",
       "      <td>44097533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-02-27</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>237.30</td>\n",
       "      <td>237.30</td>\n",
       "      <td>242.46</td>\n",
       "      <td>237.06</td>\n",
       "      <td>239.41</td>\n",
       "      <td>40625878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>241.84</td>\n",
       "      <td>241.84</td>\n",
       "      <td>242.09</td>\n",
       "      <td>230.20</td>\n",
       "      <td>236.95</td>\n",
       "      <td>55804209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-03-03</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>238.03</td>\n",
       "      <td>238.03</td>\n",
       "      <td>244.03</td>\n",
       "      <td>236.11</td>\n",
       "      <td>241.79</td>\n",
       "      <td>46873613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-03-04</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>235.93</td>\n",
       "      <td>235.93</td>\n",
       "      <td>240.07</td>\n",
       "      <td>234.68</td>\n",
       "      <td>237.71</td>\n",
       "      <td>53009183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>235.74</td>\n",
       "      <td>235.74</td>\n",
       "      <td>236.55</td>\n",
       "      <td>229.23</td>\n",
       "      <td>235.42</td>\n",
       "      <td>46987098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2025-03-06</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>235.33</td>\n",
       "      <td>235.33</td>\n",
       "      <td>237.86</td>\n",
       "      <td>233.16</td>\n",
       "      <td>234.44</td>\n",
       "      <td>44856248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2025-03-07</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>239.07</td>\n",
       "      <td>239.07</td>\n",
       "      <td>241.37</td>\n",
       "      <td>234.76</td>\n",
       "      <td>235.10</td>\n",
       "      <td>45602641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2025-03-10</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>227.48</td>\n",
       "      <td>227.48</td>\n",
       "      <td>236.16</td>\n",
       "      <td>224.22</td>\n",
       "      <td>235.54</td>\n",
       "      <td>71451281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2025-03-11</td>\n",
       "      <td>None</td>\n",
       "      <td>15022073000</td>\n",
       "      <td>220.84</td>\n",
       "      <td>220.84</td>\n",
       "      <td>225.84</td>\n",
       "      <td>217.45</td>\n",
       "      <td>223.81</td>\n",
       "      <td>73971209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Dividend Paid  Common Shares Outstanding  Last Closing Price  \\\n",
       "0  2025-02-12          None                15022073000              236.87   \n",
       "1  2025-02-13          None                15022073000              241.53   \n",
       "2  2025-02-14          None                15022073000              244.60   \n",
       "3  2025-02-18          None                15022073000              244.47   \n",
       "4  2025-02-19          None                15022073000              244.87   \n",
       "5  2025-02-20          None                15022073000              245.83   \n",
       "6  2025-02-21          None                15022073000              245.55   \n",
       "7  2025-02-24          None                15022073000              247.10   \n",
       "8  2025-02-25          None                15022073000              247.04   \n",
       "9  2025-02-26          None                15022073000              240.36   \n",
       "10 2025-02-27          None                15022073000              237.30   \n",
       "11 2025-02-28          None                15022073000              241.84   \n",
       "12 2025-03-03          None                15022073000              238.03   \n",
       "13 2025-03-04          None                15022073000              235.93   \n",
       "14 2025-03-05          None                15022073000              235.74   \n",
       "15 2025-03-06          None                15022073000              235.33   \n",
       "16 2025-03-07          None                15022073000              239.07   \n",
       "17 2025-03-10          None                15022073000              227.48   \n",
       "18 2025-03-11          None                15022073000              220.84   \n",
       "\n",
       "    Adjusted Closing Price  Highest Price  Lowest Price  Opening Price  \\\n",
       "0                   236.87         236.96        230.68         231.20   \n",
       "1                   241.53         242.34        235.57         236.91   \n",
       "2                   244.60         245.55        240.99         241.25   \n",
       "3                   244.47         245.18        241.84         244.15   \n",
       "4                   244.87         246.01        243.16         244.66   \n",
       "5                   245.83         246.78        244.29         244.94   \n",
       "6                   245.55         248.69        245.22         245.95   \n",
       "7                   247.10         248.86        244.42         244.93   \n",
       "8                   247.04         250.00        244.91         248.00   \n",
       "9                   240.36         244.98        239.13         244.33   \n",
       "10                  237.30         242.46        237.06         239.41   \n",
       "11                  241.84         242.09        230.20         236.95   \n",
       "12                  238.03         244.03        236.11         241.79   \n",
       "13                  235.93         240.07        234.68         237.71   \n",
       "14                  235.74         236.55        229.23         235.42   \n",
       "15                  235.33         237.86        233.16         234.44   \n",
       "16                  239.07         241.37        234.76         235.10   \n",
       "17                  227.48         236.16        224.22         235.54   \n",
       "18                  220.84         225.84        217.45         223.81   \n",
       "\n",
       "    Trading Volume  \n",
       "0         44996462  \n",
       "1         52138207  \n",
       "2         40185610  \n",
       "3         48111486  \n",
       "4         32140384  \n",
       "5         31037471  \n",
       "6         53011988  \n",
       "7         51031845  \n",
       "8         47275651  \n",
       "9         44097533  \n",
       "10        40625878  \n",
       "11        55804209  \n",
       "12        46873613  \n",
       "13        53009183  \n",
       "14        46987098  \n",
       "15        44856248  \n",
       "16        45602641  \n",
       "17        71451281  \n",
       "18        73971209  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stock"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
